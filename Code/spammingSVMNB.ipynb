{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0P_Sl3nIk9C",
    "outputId": "d6dff124-95b7-4a2c-840a-46ed7a99d506"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Python-Projects' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/SmallLion/Python-Projects.git\n",
    "\n",
    "#importing the dataset from the github repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9DDlXcTItrZ"
   },
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3vXrXOHIEBM"
   },
   "source": [
    "Below is the code to import the required packages through which we can perform data preprocessing on the text data. As this data is based on text, therefore, we would be applying some concepts of Natural Language Processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmDEDNmpIo2B",
    "outputId": "819b9f45-3c38-43e3-f2d0-da50f9b3d9b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Muhammad\n",
      "[nltk_data]     Waleed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Q9Q8nyB9JCZm",
    "outputId": "a7ea71e9-9182-40e1-b942-7a6c07fffdf5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham             Will Ã_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the dataset using the method of read_csv through pandas library\n",
    "df = pd.read_csv(\"Python-Projects/Spam-detection/spam.csv\", encoding = 'latin-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "_2GolQseJIT_",
    "outputId": "e9ac80a2-d47b-47e0-aa90-23263cb083e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham             Will Ã_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#passing the required columns v1 an v2, so that they can only be used in further process.\n",
    "# the v1 column contains the target values and v2 column as input values.\n",
    "df = df[['v1','v2']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sA0CpbiJRVf",
    "outputId": "dadd4c23-1263-4d8f-fb93-cf0518ab3a00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Waleed\\AppData\\Local\\Temp\\ipykernel_7792\\204087397.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['v1'] = enc.fit_transform(  df['v1']) #using the fit_transform method to convert the labels from string to numbers\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder() #creating an object of LabelEncoder so that we can apply transformation on our text data\n",
    "df['v1'] = enc.fit_transform(  df['v1']) #using the fit_transform method to convert the labels from string to numbers\n",
    "classes = {index: label for index, label in enumerate(enc.classes_)} #putting the labelled classes in a \"classes\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BK97AJHLJj7F",
    "outputId": "c4d5a6fa-9d20-4d8d-aa5c-c45591c6fcd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ham', 1: 'spam'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JTg_Z4PcJmPC"
   },
   "outputs": [],
   "source": [
    "\n",
    "def GetText(text):\n",
    "    ps = PorterStemmer() #creating an object of porterstemer through which we can apply stemming (converting words on its root)\n",
    "    text = text.lower() #converting all words into lower cases\n",
    "    #using the sub method to clean our data\n",
    "    text = re.sub(r'(http|https)://[^\\s]*', 'httpaddr', text) #replacing http address to the word 'http'\n",
    "    text = re.sub(r'[0-9+]','number',text) #replacing numbers to the word 'number'\n",
    "    text = re.sub(r'[$]+', 'dollar', text) #replacing dollar signs to the word 'dollar'\n",
    "    text = re.sub(r'<[^<>]+>', ' ', text) #replacing unusual signs\n",
    "    text = re.sub(r'[^\\s]+@[^\\s]+', 'emailaddr', text) #converting email address to the word 'emailaddr'\n",
    "\n",
    "    words = word_tokenize(text) #passing our cleaned text into the function word_tokenize to create tokens\n",
    "    for i in range(len(words)):\n",
    "       words[i] = re.sub(r'[^a-zA-Z0-9]', '', words[i]) \n",
    "       words[i] = ps.stem(words[i]) #applying stemming to the words one by one and saving them in the original list\n",
    "    words = [word for word in words if len(word) >= 1] #now creating the list of words and removing the words from the list which are \n",
    "    return words #returning the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zJOQ8DSmKGRg"
   },
   "outputs": [],
   "source": [
    "def ProcessVocab(text, n):\n",
    "    vocab = {} #creating an emtpy dictionary to store values in the pair of key and value\n",
    "    for i in range(len(text)): #creating a loop to iterate with respect to the numebr of texts\n",
    "        text[i] = GetText(text[i]) #passing each text in the respective index one by one in the GetText function so that they can be cleaned\n",
    "        for word in text[i]: #getting each word from the text \n",
    "            if word in vocab.keys():\n",
    "                vocab[word] += 1\n",
    "            else:\n",
    "                vocab[word] = 1\n",
    "        #with the help of this loop we are adding assigning their frequency number to each unique word in the list of texts \n",
    "    vocab = sorted(vocab.items(), key = lambda x: x[1], reverse = True) #sorting those words with respect to their numbers\n",
    "    vocab = list(map( lambda x:x[0]  , vocab[0: n])) #converting the vocab ito list\n",
    "    vocab = {index: word for index, word in enumerate(vocab)} #now reversing the list and words\n",
    "    \n",
    "    return vocab #returning the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2Ff8vIMKcB9",
    "outputId": "3197d25b-c31e-4e0f-8443-8bfa025ffc6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'i',\n",
       " 1: 'to',\n",
       " 2: 'you',\n",
       " 3: 'a',\n",
       " 4: 'the',\n",
       " 5: 'number',\n",
       " 6: 'u',\n",
       " 7: 'and',\n",
       " 8: 'it',\n",
       " 9: 'is',\n",
       " 10: 'in',\n",
       " 11: 'me',\n",
       " 12: 'my',\n",
       " 13: 'for',\n",
       " 14: 'your',\n",
       " 15: 'call',\n",
       " 16: 'have',\n",
       " 17: 'do',\n",
       " 18: 'that',\n",
       " 19: 'of',\n",
       " 20: 's',\n",
       " 21: 'on',\n",
       " 22: 'are',\n",
       " 23: 'now',\n",
       " 24: 'so',\n",
       " 25: 'go',\n",
       " 26: 'get',\n",
       " 27: 'not',\n",
       " 28: 'but',\n",
       " 29: 'be',\n",
       " 30: 'or',\n",
       " 31: 'm',\n",
       " 32: 'can',\n",
       " 33: 'at',\n",
       " 34: 'numbernumbernumb',\n",
       " 35: 'we',\n",
       " 36: 'will',\n",
       " 37: 'if',\n",
       " 38: 'ur',\n",
       " 39: 'with',\n",
       " 40: 'numbernumbernumbernumbernumbernumbernumbernumbernumbernumbernumb',\n",
       " 41: 'nt',\n",
       " 42: 'just',\n",
       " 43: 'no',\n",
       " 44: 'thi',\n",
       " 45: 'how',\n",
       " 46: 'gt',\n",
       " 47: 'lt',\n",
       " 48: 'up',\n",
       " 49: 'what',\n",
       " 50: 'come',\n",
       " 51: 'when',\n",
       " 52: 'ok',\n",
       " 53: 'from',\n",
       " 54: 'free',\n",
       " 55: 'know',\n",
       " 56: 'all',\n",
       " 57: 'out',\n",
       " 58: 'numbernumbernumbernumb',\n",
       " 59: 'numbernumbernumbernumbernumb',\n",
       " 60: 'like',\n",
       " 61: 'got',\n",
       " 62: 'love',\n",
       " 63: 'day',\n",
       " 64: 'time',\n",
       " 65: 'wa',\n",
       " 66: 'want',\n",
       " 67: 'good',\n",
       " 68: 'then',\n",
       " 69: 'll',\n",
       " 70: 'there',\n",
       " 71: 'he',\n",
       " 72: 'text',\n",
       " 73: 'am',\n",
       " 74: 'onli',\n",
       " 75: 'send',\n",
       " 76: 'hi',\n",
       " 77: 'numbernumb',\n",
       " 78: 'need',\n",
       " 79: 'one',\n",
       " 80: 'txt',\n",
       " 81: 'as',\n",
       " 82: 'today',\n",
       " 83: 'see',\n",
       " 84: 'by',\n",
       " 85: 'take',\n",
       " 86: 'think',\n",
       " 87: 'about',\n",
       " 88: 'she',\n",
       " 89: 'did',\n",
       " 90: 'home',\n",
       " 91: 'repli',\n",
       " 92: 'lor',\n",
       " 93: 'r',\n",
       " 94: 'stop',\n",
       " 95: 'sorri',\n",
       " 96: 'tell',\n",
       " 97: 'still',\n",
       " 98: 'back',\n",
       " 99: 'dont',\n",
       " 100: 'mobil',\n",
       " 101: 'da',\n",
       " 102: 'our',\n",
       " 103: 'n',\n",
       " 104: 'make',\n",
       " 105: 'phone',\n",
       " 106: 'say',\n",
       " 107: 'ha',\n",
       " 108: 'pleas',\n",
       " 109: 'd',\n",
       " 110: 'new',\n",
       " 111: 'work',\n",
       " 112: 'later',\n",
       " 113: 'ani',\n",
       " 114: 'week',\n",
       " 115: 'they',\n",
       " 116: 'ask',\n",
       " 117: 'been',\n",
       " 118: 'miss',\n",
       " 119: 'hope',\n",
       " 120: 'pl',\n",
       " 121: 'an',\n",
       " 122: 'her',\n",
       " 123: 'meet',\n",
       " 124: 'k',\n",
       " 125: 'messag',\n",
       " 126: 'who',\n",
       " 127: 'here',\n",
       " 128: 'some',\n",
       " 129: 'happi',\n",
       " 130: 'night',\n",
       " 131: 'wait',\n",
       " 132: 'well',\n",
       " 133: 'dear',\n",
       " 134: 'where',\n",
       " 135: 'great',\n",
       " 136: 'claim',\n",
       " 137: 'thing',\n",
       " 138: 'oh',\n",
       " 139: 'tri',\n",
       " 140: 'much',\n",
       " 141: 'wat',\n",
       " 142: 'give',\n",
       " 143: 'c',\n",
       " 144: 'hey',\n",
       " 145: 'him',\n",
       " 146: 'more',\n",
       " 147: 're',\n",
       " 148: 'na',\n",
       " 149: 'too',\n",
       " 150: 'friend',\n",
       " 151: 'had',\n",
       " 152: 'thank',\n",
       " 153: 'way',\n",
       " 154: 'should',\n",
       " 155: 'msg',\n",
       " 156: 've',\n",
       " 157: 'prize',\n",
       " 158: 'right',\n",
       " 159: 'ye',\n",
       " 160: 'feel',\n",
       " 161: 'let',\n",
       " 162: 'im',\n",
       " 163: 'wan',\n",
       " 164: 'even',\n",
       " 165: 'alreadi',\n",
       " 166: 'pick',\n",
       " 167: 'tomorrow',\n",
       " 168: 'after',\n",
       " 169: 'said',\n",
       " 170: 'yeah',\n",
       " 171: 'min',\n",
       " 172: 'realli',\n",
       " 173: 'amp',\n",
       " 174: 'leav',\n",
       " 175: 'e',\n",
       " 176: 'babe',\n",
       " 177: 'care',\n",
       " 178: 'co',\n",
       " 179: 'whi',\n",
       " 180: 'them',\n",
       " 181: 'morn',\n",
       " 182: 'would',\n",
       " 183: 'veri',\n",
       " 184: 'win',\n",
       " 185: 'life',\n",
       " 186: 'last',\n",
       " 187: 'sleep',\n",
       " 188: 'sure',\n",
       " 189: 'servic',\n",
       " 190: 'keep',\n",
       " 191: 'use',\n",
       " 192: 'ill',\n",
       " 193: 'cash',\n",
       " 194: 'find',\n",
       " 195: 'year',\n",
       " 196: 'contact',\n",
       " 197: 't',\n",
       " 198: 'lol',\n",
       " 199: 'anyth',\n",
       " 200: 'buy',\n",
       " 201: 'tone',\n",
       " 202: 'won',\n",
       " 203: 'look',\n",
       " 204: 'wish',\n",
       " 205: 'everi',\n",
       " 206: 'nokia',\n",
       " 207: 'start',\n",
       " 208: 'smile',\n",
       " 209: 'also',\n",
       " 210: 'sent',\n",
       " 211: 'urgent',\n",
       " 212: 'watch',\n",
       " 213: 'someth',\n",
       " 214: 'show',\n",
       " 215: 'befor',\n",
       " 216: 'over',\n",
       " 217: 'cant',\n",
       " 218: 'b',\n",
       " 219: 'finish',\n",
       " 220: 'end',\n",
       " 221: 'award',\n",
       " 222: 'again',\n",
       " 223: 'were',\n",
       " 224: 'could',\n",
       " 225: 'place',\n",
       " 226: 'us',\n",
       " 227: 'other',\n",
       " 228: 'first',\n",
       " 229: 'custom',\n",
       " 230: 'next',\n",
       " 231: 'someon',\n",
       " 232: 'guy',\n",
       " 233: 'around',\n",
       " 234: 'talk',\n",
       " 235: 'tonight',\n",
       " 236: 'help',\n",
       " 237: 'which',\n",
       " 238: 'late',\n",
       " 239: 'went',\n",
       " 240: 'word',\n",
       " 241: 'ca',\n",
       " 242: 'collect',\n",
       " 243: 'chat',\n",
       " 244: 'off',\n",
       " 245: 'gon',\n",
       " 246: 'soon',\n",
       " 247: 'money',\n",
       " 248: 'person',\n",
       " 249: 'mani',\n",
       " 250: 'per',\n",
       " 251: 'nice',\n",
       " 252: 'plan',\n",
       " 253: 'ya',\n",
       " 254: 'live',\n",
       " 255: 'down',\n",
       " 256: 'alway',\n",
       " 257: 'minut',\n",
       " 258: 'dun',\n",
       " 259: 'check',\n",
       " 260: 'gud',\n",
       " 261: 'name',\n",
       " 262: 'lot',\n",
       " 263: 'told',\n",
       " 264: 'special',\n",
       " 265: 'mean',\n",
       " 266: 'v',\n",
       " 267: 'girl',\n",
       " 268: 'heart',\n",
       " 269: 'hour',\n",
       " 270: 'x',\n",
       " 271: 'hello',\n",
       " 272: 'reach',\n",
       " 273: 'peopl',\n",
       " 274: 'haha',\n",
       " 275: 'shop',\n",
       " 276: 'fine',\n",
       " 277: 'same',\n",
       " 278: 'guarante',\n",
       " 279: 'yet',\n",
       " 280: 'happen',\n",
       " 281: 'thk',\n",
       " 282: 'may',\n",
       " 283: 'done',\n",
       " 284: 'offer',\n",
       " 285: 'thought',\n",
       " 286: 'play',\n",
       " 287: 'doe',\n",
       " 288: 'class',\n",
       " 289: 'holiday',\n",
       " 290: 'line',\n",
       " 291: 'fuck',\n",
       " 292: 'receiv',\n",
       " 293: 'lunch',\n",
       " 294: 'best',\n",
       " 295: 'god',\n",
       " 296: 'stuff',\n",
       " 297: 'eat',\n",
       " 298: 'car',\n",
       " 299: 'man',\n",
       " 300: 'job',\n",
       " 301: 'draw',\n",
       " 302: 'mayb',\n",
       " 303: 'bit',\n",
       " 304: 'never',\n",
       " 305: 'y',\n",
       " 306: 'few',\n",
       " 307: 'enjoy',\n",
       " 308: 'month',\n",
       " 309: 'worri',\n",
       " 310: 'yup',\n",
       " 311: 'sm',\n",
       " 312: 'account',\n",
       " 313: 'long',\n",
       " 314: 'drive',\n",
       " 315: 'guess',\n",
       " 316: 'better',\n",
       " 317: 'dat',\n",
       " 318: 'readi',\n",
       " 319: 'problem',\n",
       " 320: 'mind',\n",
       " 321: 'chanc',\n",
       " 322: 'date',\n",
       " 323: 'cool',\n",
       " 324: 'cs',\n",
       " 325: 'world',\n",
       " 326: 'latest',\n",
       " 327: 'cost',\n",
       " 328: 'pay',\n",
       " 329: 'weekend',\n",
       " 330: 'wonder',\n",
       " 331: 'room',\n",
       " 332: 'sir',\n",
       " 333: 'boy',\n",
       " 334: 'becaus',\n",
       " 335: 'than',\n",
       " 336: 'didnt',\n",
       " 337: 'bring',\n",
       " 338: 'quit',\n",
       " 339: 'lar',\n",
       " 340: 'half',\n",
       " 341: 'yo',\n",
       " 342: 'noth',\n",
       " 343: 'hous',\n",
       " 344: 'book',\n",
       " 345: 'game',\n",
       " 346: 'numberst',\n",
       " 347: 'sweet',\n",
       " 348: 'anoth',\n",
       " 349: 'luv',\n",
       " 350: 'liao',\n",
       " 351: 'big',\n",
       " 352: 'voucher',\n",
       " 353: 'question',\n",
       " 354: 'select',\n",
       " 355: 'camera',\n",
       " 356: 'charg',\n",
       " 357: 'real',\n",
       " 358: 'birthday',\n",
       " 359: 'landlin',\n",
       " 360: 'stay',\n",
       " 361: 'into',\n",
       " 362: 'shit',\n",
       " 363: 'kiss',\n",
       " 364: 'put',\n",
       " 365: 'speak',\n",
       " 366: 'rememb',\n",
       " 367: 'dinner',\n",
       " 368: 'rington',\n",
       " 369: 'numbernumbernumberppm',\n",
       " 370: 'join',\n",
       " 371: 'ju',\n",
       " 372: 'box',\n",
       " 373: 'ever',\n",
       " 374: 'pic',\n",
       " 375: 'rate',\n",
       " 376: 'ah',\n",
       " 377: 'numbernumberp',\n",
       " 378: 'might',\n",
       " 379: 'actual',\n",
       " 380: 'point',\n",
       " 381: 'final',\n",
       " 382: 'appli',\n",
       " 383: 'earli',\n",
       " 384: 'network',\n",
       " 385: 'di',\n",
       " 386: 'hear',\n",
       " 387: 'onc',\n",
       " 388: 'chang',\n",
       " 389: 'aight',\n",
       " 390: 'babi',\n",
       " 391: 'probabl',\n",
       " 392: 'fun',\n",
       " 393: 'xxx',\n",
       " 394: 'wont',\n",
       " 395: 'run',\n",
       " 396: 'part',\n",
       " 397: 'pa',\n",
       " 398: 'bed',\n",
       " 399: 'hurt',\n",
       " 400: 'anyway',\n",
       " 401: 'answer',\n",
       " 402: 'po',\n",
       " 403: 'video',\n",
       " 404: 'two',\n",
       " 405: 'orang',\n",
       " 406: 'den',\n",
       " 407: 'bad',\n",
       " 408: 'princess',\n",
       " 409: 'code',\n",
       " 410: 'between',\n",
       " 411: 'forgot',\n",
       " 412: 'easi',\n",
       " 413: 'thanx',\n",
       " 414: 'wake',\n",
       " 415: 'shall',\n",
       " 416: 'dunno',\n",
       " 417: 'sat',\n",
       " 418: 'offic',\n",
       " 419: 'numbernumbernumbernumbernumbernumb',\n",
       " 420: 'left',\n",
       " 421: 'numbernd',\n",
       " 422: 'frnd',\n",
       " 423: 'littl',\n",
       " 424: 'dream',\n",
       " 425: 'tv',\n",
       " 426: 'leh',\n",
       " 427: 'walk',\n",
       " 428: 'face',\n",
       " 429: 'dad',\n",
       " 430: 'enough',\n",
       " 431: 'bu',\n",
       " 432: 'pain',\n",
       " 433: 'afternoon',\n",
       " 434: 'movi',\n",
       " 435: 'school',\n",
       " 436: 'those',\n",
       " 437: 'sound',\n",
       " 438: 'everyth',\n",
       " 439: 'made',\n",
       " 440: 'numbernumbernumberp',\n",
       " 441: 'detail',\n",
       " 442: 'mate',\n",
       " 443: 'pound',\n",
       " 444: 'most',\n",
       " 445: 'mail',\n",
       " 446: 'without',\n",
       " 447: 'xma',\n",
       " 448: 'tmr',\n",
       " 449: 'lose',\n",
       " 450: 'read',\n",
       " 451: 'post',\n",
       " 452: 'bore',\n",
       " 453: 'while',\n",
       " 454: 'gift',\n",
       " 455: 'await',\n",
       " 456: 'until',\n",
       " 457: 'wif',\n",
       " 458: 'though',\n",
       " 459: 'credit',\n",
       " 460: 'decid',\n",
       " 461: 'sinc',\n",
       " 462: 'came',\n",
       " 463: 'test',\n",
       " 464: 'must',\n",
       " 465: 'sexi',\n",
       " 466: 'hav',\n",
       " 467: 'town',\n",
       " 468: 'entri',\n",
       " 469: 'goe',\n",
       " 470: 'set',\n",
       " 471: 'colour',\n",
       " 472: 'uk',\n",
       " 473: 'lesson',\n",
       " 474: 'close',\n",
       " 475: 'havent',\n",
       " 476: 'abt',\n",
       " 477: 'wk',\n",
       " 478: 'okay',\n",
       " 479: 'price',\n",
       " 480: 'numberth',\n",
       " 481: 'til',\n",
       " 482: 'abl',\n",
       " 483: 'import',\n",
       " 484: 'true',\n",
       " 485: 'updat',\n",
       " 486: 'mob',\n",
       " 487: 'juz',\n",
       " 488: 'enter',\n",
       " 489: 'order',\n",
       " 490: 'bath',\n",
       " 491: 'smoke',\n",
       " 492: 'decim',\n",
       " 493: 'plz',\n",
       " 494: 'wot',\n",
       " 495: 'poli',\n",
       " 496: 'drink',\n",
       " 497: 'away',\n",
       " 498: 'plu',\n",
       " 499: 'wife',\n",
       " 500: 'till',\n",
       " 501: 'wo',\n",
       " 502: 'saw',\n",
       " 503: 'yesterday',\n",
       " 504: 'hair',\n",
       " 505: 'wen',\n",
       " 506: 'els',\n",
       " 507: 'top',\n",
       " 508: 'bt',\n",
       " 509: 'music',\n",
       " 510: 'weekli',\n",
       " 511: 'dude',\n",
       " 512: 'beauti',\n",
       " 513: 'attempt',\n",
       " 514: 'de',\n",
       " 515: 'drop',\n",
       " 516: 'valid',\n",
       " 517: 'alright',\n",
       " 518: 'invit',\n",
       " 519: 'doubl',\n",
       " 520: 'trip',\n",
       " 521: 'food',\n",
       " 522: 'haf',\n",
       " 523: 'hand',\n",
       " 524: 'oso',\n",
       " 525: 'head',\n",
       " 526: 'friendship',\n",
       " 527: 'onlin',\n",
       " 528: 'lei',\n",
       " 529: 'search',\n",
       " 530: 'ard',\n",
       " 531: 'deliveri',\n",
       " 532: 'yourself',\n",
       " 533: 'busi',\n",
       " 534: 'yr',\n",
       " 535: 'coz',\n",
       " 536: 'open',\n",
       " 537: 'si',\n",
       " 538: 'ring',\n",
       " 539: 'hot',\n",
       " 540: 'either',\n",
       " 541: 'these',\n",
       " 542: 'sch',\n",
       " 543: 'famili',\n",
       " 544: 'goin',\n",
       " 545: 'brother',\n",
       " 546: 'mom',\n",
       " 547: 'second',\n",
       " 548: 'bonu',\n",
       " 549: 'caus',\n",
       " 550: 'address',\n",
       " 551: 'inform',\n",
       " 552: 'player',\n",
       " 553: 'complet',\n",
       " 554: 'stori',\n",
       " 555: 'id',\n",
       " 556: 'nite',\n",
       " 557: 'g',\n",
       " 558: 'hold',\n",
       " 559: 'wid',\n",
       " 560: 'full',\n",
       " 561: 'tot',\n",
       " 562: 'sae',\n",
       " 563: 'togeth',\n",
       " 564: 'email',\n",
       " 565: 'sad',\n",
       " 566: 'forget',\n",
       " 567: 'old',\n",
       " 568: 'match',\n",
       " 569: 'emailaddr',\n",
       " 570: 'content',\n",
       " 571: 'believ',\n",
       " 572: 'studi',\n",
       " 573: 'touch',\n",
       " 574: 'both',\n",
       " 575: 'noe',\n",
       " 576: 'club',\n",
       " 577: 'oki',\n",
       " 578: 'numberu',\n",
       " 579: 'chikku',\n",
       " 580: 'reason',\n",
       " 581: 'huh',\n",
       " 582: 'eve',\n",
       " 583: 'land',\n",
       " 584: 'listen',\n",
       " 585: 'train',\n",
       " 586: 'murder',\n",
       " 587: 'numbernumberpmin',\n",
       " 588: 'treat',\n",
       " 589: 'httpaddr',\n",
       " 590: 'aft',\n",
       " 591: 'fri',\n",
       " 592: 'tomo',\n",
       " 593: 'congrat',\n",
       " 594: 'took',\n",
       " 595: 'numbernumberhr',\n",
       " 596: 'privat',\n",
       " 597: 'expir',\n",
       " 598: 'dog',\n",
       " 599: 'age',\n",
       " 600: 'everyon',\n",
       " 601: 'parent',\n",
       " 602: 'grnumber',\n",
       " 603: 'awesom',\n",
       " 604: 'break',\n",
       " 605: 'die',\n",
       " 606: 'unsubscrib',\n",
       " 607: 'simpl',\n",
       " 608: 'mum',\n",
       " 609: 'rite',\n",
       " 610: 'caller',\n",
       " 611: 'news',\n",
       " 612: 'tho',\n",
       " 613: 'move',\n",
       " 614: 'ta',\n",
       " 615: 'download',\n",
       " 616: 'prob',\n",
       " 617: 'statement',\n",
       " 618: 'fanci',\n",
       " 619: 'compani',\n",
       " 620: 'wil',\n",
       " 621: 'reveal',\n",
       " 622: 'angri',\n",
       " 623: 'choos',\n",
       " 624: 'sort',\n",
       " 625: 'card',\n",
       " 626: 'sister',\n",
       " 627: 'valentin',\n",
       " 628: 'current',\n",
       " 629: 'gd',\n",
       " 630: 'mine',\n",
       " 631: 'neva',\n",
       " 632: 'pub',\n",
       " 633: 'laugh',\n",
       " 634: 'anyon',\n",
       " 635: 'auction',\n",
       " 636: 'avail',\n",
       " 637: 'joke',\n",
       " 638: 'valu',\n",
       " 639: 'seem',\n",
       " 640: 'lucki',\n",
       " 641: 'bday',\n",
       " 642: 'type',\n",
       " 643: 'each',\n",
       " 644: 'bank',\n",
       " 645: 'worth',\n",
       " 646: 'found',\n",
       " 647: 'colleg',\n",
       " 648: 'park',\n",
       " 649: 'whatev',\n",
       " 650: 'knw',\n",
       " 651: 'sell',\n",
       " 652: 'understand',\n",
       " 653: 'alon',\n",
       " 654: 'winner',\n",
       " 655: 'pobox',\n",
       " 656: 'smth',\n",
       " 657: 'saturday',\n",
       " 658: 'usual',\n",
       " 659: 'pass',\n",
       " 660: 'song',\n",
       " 661: 'save',\n",
       " 662: 'oper',\n",
       " 663: 'ticket',\n",
       " 664: 'gone',\n",
       " 665: 'hit',\n",
       " 666: 'uncl',\n",
       " 667: 'unredeem',\n",
       " 668: 'identifi',\n",
       " 669: 'hard',\n",
       " 670: 'carlo',\n",
       " 671: 'log',\n",
       " 672: 'boytoy',\n",
       " 673: 'bill',\n",
       " 674: 'exam',\n",
       " 675: 'secret',\n",
       " 676: 'congratul',\n",
       " 677: 'anytim',\n",
       " 678: 'far',\n",
       " 679: 'return',\n",
       " 680: 'numbernumbernumberpmsg',\n",
       " 681: 'mobileupdnumb',\n",
       " 682: 'welcom',\n",
       " 683: 'kind',\n",
       " 684: 'visit',\n",
       " 685: 'outsid',\n",
       " 686: 'o',\n",
       " 687: 'sun',\n",
       " 688: 'sit',\n",
       " 689: 'parti',\n",
       " 690: 'surpris',\n",
       " 691: 'crazi',\n",
       " 692: 'camcord',\n",
       " 693: 'cut',\n",
       " 694: 'follow',\n",
       " 695: 'xx',\n",
       " 696: 'rain',\n",
       " 697: 'friday',\n",
       " 698: 'mu',\n",
       " 699: 'their',\n",
       " 700: 'ltd',\n",
       " 701: 'wit',\n",
       " 702: 'darlin',\n",
       " 703: 'goodmorn',\n",
       " 704: 'oredi',\n",
       " 705: 'case',\n",
       " 706: 'tel',\n",
       " 707: 'fone',\n",
       " 708: 'light',\n",
       " 709: 'project',\n",
       " 710: 'bout',\n",
       " 711: 'th',\n",
       " 712: 'cum',\n",
       " 713: 'nope',\n",
       " 714: 'pretti',\n",
       " 715: 'sea',\n",
       " 716: 'fast',\n",
       " 717: 'clean',\n",
       " 718: 'drug',\n",
       " 719: 'gal',\n",
       " 720: 'wrong',\n",
       " 721: 'chennai',\n",
       " 722: 'tht',\n",
       " 723: 'wkli',\n",
       " 724: 'freemsg',\n",
       " 725: 'hungri',\n",
       " 726: 'confirm',\n",
       " 727: 'whole',\n",
       " 728: 'correct',\n",
       " 729: 'comput',\n",
       " 730: 'hmm',\n",
       " 731: 'spend',\n",
       " 732: 'dollar',\n",
       " 733: 'cours',\n",
       " 734: 'mrng',\n",
       " 735: 'ga',\n",
       " 736: 'meant',\n",
       " 737: 'fix',\n",
       " 738: 'cd',\n",
       " 739: 'unlimit',\n",
       " 740: 'own',\n",
       " 741: 'interest',\n",
       " 742: 'tc',\n",
       " 743: 'jay',\n",
       " 744: 'rock',\n",
       " 745: 'ad',\n",
       " 746: 'ten',\n",
       " 747: 'suppos',\n",
       " 748: 'differ',\n",
       " 749: 'scream',\n",
       " 750: 'remov',\n",
       " 751: 'term',\n",
       " 752: 'frm',\n",
       " 753: 'kid',\n",
       " 754: 'snow',\n",
       " 755: 'opt',\n",
       " 756: 'bnumber',\n",
       " 757: 'least',\n",
       " 758: 'press',\n",
       " 759: 'info',\n",
       " 760: 'promis',\n",
       " 761: 'turn',\n",
       " 762: 'catch',\n",
       " 763: 'almost',\n",
       " 764: 'etc',\n",
       " 765: 'hee',\n",
       " 766: 'shower',\n",
       " 767: 'mah',\n",
       " 768: 'felt',\n",
       " 769: 'quiz',\n",
       " 770: 'tire',\n",
       " 771: 'ninumb',\n",
       " 772: 'wine',\n",
       " 773: 'joy',\n",
       " 774: 'mr',\n",
       " 775: 'doesnt',\n",
       " 776: 'march',\n",
       " 777: 'side',\n",
       " 778: 'fr',\n",
       " 779: 'dnt',\n",
       " 780: 'singl',\n",
       " 781: 'blue',\n",
       " 782: 'bslvyl',\n",
       " 783: 'lost',\n",
       " 784: 'christma',\n",
       " 785: 'figur',\n",
       " 786: 'moment',\n",
       " 787: 'st',\n",
       " 788: 'forward',\n",
       " 789: 'motorola',\n",
       " 790: 'coupl',\n",
       " 791: 'ass',\n",
       " 792: 'pm',\n",
       " 793: 'savamob',\n",
       " 794: 'sub',\n",
       " 795: 'within',\n",
       " 796: 'marri',\n",
       " 797: 'yar',\n",
       " 798: 'area',\n",
       " 799: 'paper',\n",
       " 800: 'sex',\n",
       " 801: 'earlier',\n",
       " 802: 'don',\n",
       " 803: 'support',\n",
       " 804: 'film',\n",
       " 805: 'fren',\n",
       " 806: 'w',\n",
       " 807: 'father',\n",
       " 808: 'reward',\n",
       " 809: 'eh',\n",
       " 810: 'nation',\n",
       " 811: 'eg',\n",
       " 812: 'crave',\n",
       " 813: 'hospit',\n",
       " 814: 'wow',\n",
       " 815: 'complimentari',\n",
       " 816: 'stand',\n",
       " 817: 'load',\n",
       " 818: 'askd',\n",
       " 819: 'direct',\n",
       " 820: 'activ',\n",
       " 821: 'safe',\n",
       " 822: 'deal',\n",
       " 823: 'connect',\n",
       " 824: 'semest',\n",
       " 825: 'laptop',\n",
       " 826: 'swing',\n",
       " 827: 'normal',\n",
       " 828: 'via',\n",
       " 829: 'ago',\n",
       " 830: 'seen',\n",
       " 831: 'slow',\n",
       " 832: 'rental',\n",
       " 833: 'india',\n",
       " 834: 'rent',\n",
       " 835: 'ipod',\n",
       " 836: 'ladi',\n",
       " 837: 'through',\n",
       " 838: 'remind',\n",
       " 839: 'gym',\n",
       " 840: 'darren',\n",
       " 841: 'eye',\n",
       " 842: 'store',\n",
       " 843: 'ugh',\n",
       " 844: 'extra',\n",
       " 845: 'knew',\n",
       " 846: 'photo',\n",
       " 847: 'truth',\n",
       " 848: 'heard',\n",
       " 849: 'fill',\n",
       " 850: 'grin',\n",
       " 851: 'luck',\n",
       " 852: 'difficult',\n",
       " 853: 'john',\n",
       " 854: 'comp',\n",
       " 855: 'usf',\n",
       " 856: 'request',\n",
       " 857: 'copi',\n",
       " 858: 'numberday',\n",
       " 859: 'sunday',\n",
       " 860: 'link',\n",
       " 861: 'comin',\n",
       " 862: 'cheer',\n",
       " 863: 'abiola',\n",
       " 864: 'rpli',\n",
       " 865: 'includ',\n",
       " 866: 'loan',\n",
       " 867: 'page',\n",
       " 868: 'txting',\n",
       " 869: 'sometim',\n",
       " 870: 'hmmm',\n",
       " 871: 'muz',\n",
       " 872: 'numberpm',\n",
       " 873: 'orchard',\n",
       " 874: 'kate',\n",
       " 875: 'ive',\n",
       " 876: 'rs',\n",
       " 877: 'regist',\n",
       " 878: 'bcoz',\n",
       " 879: 'teach',\n",
       " 880: 'road',\n",
       " 881: 'expect',\n",
       " 882: 'lover',\n",
       " 883: 'disturb',\n",
       " 884: 'wana',\n",
       " 885: 'somebodi',\n",
       " 886: 'rest',\n",
       " 887: 'small',\n",
       " 888: 'met',\n",
       " 889: 'discount',\n",
       " 890: 'numbernumbernumbernumbernumbernumbernumb',\n",
       " 891: 'monday',\n",
       " 892: 'fight',\n",
       " 893: 'silent',\n",
       " 894: 'warm',\n",
       " 895: 'door',\n",
       " 896: 'idea',\n",
       " 897: 'possibl',\n",
       " 898: 'fall',\n",
       " 899: 'whenev',\n",
       " 900: 'cancel',\n",
       " 901: 'fantasi',\n",
       " 902: 'fact',\n",
       " 903: 'slowli',\n",
       " 904: 'polic',\n",
       " 905: 'hr',\n",
       " 906: 'nah',\n",
       " 907: 'callertun',\n",
       " 908: 'wap',\n",
       " 909: 'england',\n",
       " 910: 'myself',\n",
       " 911: 'sick',\n",
       " 912: 'oop',\n",
       " 913: 'red',\n",
       " 914: 'numbernumbernumberpm',\n",
       " 915: 'situat',\n",
       " 916: 'short',\n",
       " 917: 'recent',\n",
       " 918: 'il',\n",
       " 919: 'repres',\n",
       " 920: 'gave',\n",
       " 921: 'men',\n",
       " 922: 'apart',\n",
       " 923: 'quot',\n",
       " 924: 'del',\n",
       " 925: 'soni',\n",
       " 926: 'lovabl',\n",
       " 927: 'pray',\n",
       " 928: 'wast',\n",
       " 929: 'trust',\n",
       " 930: 'sign',\n",
       " 931: 'kick',\n",
       " 932: 'admir',\n",
       " 933: 'deep',\n",
       " 934: 'hmv',\n",
       " 935: 'stupid',\n",
       " 936: 'sim',\n",
       " 937: 'somewher',\n",
       " 938: 'merri',\n",
       " 939: 'pete',\n",
       " 940: 'record',\n",
       " 941: 'immedi',\n",
       " 942: 'access',\n",
       " 943: 'custcar',\n",
       " 944: 'ex',\n",
       " 945: 'woke',\n",
       " 946: 'mm',\n",
       " 947: 'yep',\n",
       " 948: 'voic',\n",
       " 949: 'ldn',\n",
       " 950: 'style',\n",
       " 951: 'boxnumbernumbernumb',\n",
       " 952: 'water',\n",
       " 953: 'opinion',\n",
       " 954: 'less',\n",
       " 955: 'member',\n",
       " 956: 'across',\n",
       " 957: 'cheap',\n",
       " 958: 'em',\n",
       " 959: 'ts',\n",
       " 960: 'ho',\n",
       " 961: 'gap',\n",
       " 962: 'fantast',\n",
       " 963: 'glad',\n",
       " 964: 'summer',\n",
       " 965: 'bag',\n",
       " 966: 'gettin',\n",
       " 967: 'wed',\n",
       " 968: 'poor',\n",
       " 969: 'asap',\n",
       " 970: 'otherwis',\n",
       " 971: 'ntt',\n",
       " 972: 'nyt',\n",
       " 973: 'convey',\n",
       " 974: 'regard',\n",
       " 975: 'p',\n",
       " 976: 'doctor',\n",
       " 977: 'energi',\n",
       " 978: 'numberhr',\n",
       " 979: 'write',\n",
       " 980: 'cover',\n",
       " 981: 'natur',\n",
       " 982: 'doin',\n",
       " 983: 'hw',\n",
       " 984: 'excus',\n",
       " 985: 'med',\n",
       " 986: 'empti',\n",
       " 987: 'std',\n",
       " 988: 'bless',\n",
       " 989: 'serious',\n",
       " 990: 'mark',\n",
       " 991: 'forev',\n",
       " 992: 'password',\n",
       " 993: 'boss',\n",
       " 994: 'flight',\n",
       " 995: 'dollarnumbernumbernumb',\n",
       " 996: 'app',\n",
       " 997: 'sunshin',\n",
       " 998: 'lazi',\n",
       " 999: 'lect',\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProcessVocab(df['v2'].to_list(), 10000) #displaying the list of vocab. In the function, we are passing two parameters: the texts and vocab limit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "n9Y4UcigKkJL"
   },
   "outputs": [],
   "source": [
    "def Key(data, value):\n",
    "    for k, v in data.items(): #iterating the kay,value pair from the data\n",
    "        if v == value: #returning the key of the value if it exists in the data dictionary\n",
    "            return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zfQOjDAHLB4z"
   },
   "outputs": [],
   "source": [
    "def getIndices(text, vocab):\n",
    "    indexes = set() #creating a data structure of set. To add unique values in the lsit\n",
    "    for w in text: #iterating words from the text one by one\n",
    "        if w in vocab.values(): #checking if the word exists in the vocab library\n",
    "            indexes.add(Key(vocab, w)) #if yes, then we will get its key from the KEY function, by passing the vocab and the respective word\n",
    "            \n",
    "    return indexes #returning the indexes\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MFLFaO6ULP0C"
   },
   "outputs": [],
   "source": [
    "def CreateColumns(indexes, n):\n",
    "    array = np.zeros(n) #creating an array containing entire zero values with the length 'n'.\n",
    "    for i in indexes:array[i] = 1 #putting the value 1 against the respective indexes, where all words acts as a feature. \n",
    "    return array #returning the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aPWIWf25Lgi4"
   },
   "outputs": [],
   "source": [
    "vocab_length =10000 #creating the vocab upto 10000 in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UG9Mr6xoLkbA"
   },
   "outputs": [],
   "source": [
    "vocab = ProcessVocab(df['v2'].to_list(), vocab_length) #passing the input text data and vocab length to process the text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "U3Q9lkPVLsOb"
   },
   "outputs": [],
   "source": [
    "text = df['v2'].to_list() #converting our text data into list\n",
    "text = list(map(lambda x: GetText(x), text))# now passing the list into the get text function and in return converting the output into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "afs8FwwnL1je"
   },
   "outputs": [],
   "source": [
    "xdf = list(map(lambda x: CreateColumns(getIndices(x, vocab), vocab_length), text)) #passing the vocab and vocab length, along with the text in the get indeices function then passing the returned data \n",
    "# into the create column functions so that they can be converted into list\n",
    "xdf = pd.DataFrame(np.array(xdf).astype(np.int16)) #now converting the columns created into dataframe with integer base 16 datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "8J0x5u9oMO0P"
   },
   "outputs": [],
   "source": [
    "Y = df['v1'].iloc[np.append(df[df['v1']  == 0].index[:100], \n",
    "          df[df['v1']  == 1].index[:100]\n",
    "          )]\n",
    "# now adding saving the processed target values in the Y variables. To save time, we are just selecting 100 samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "yVe47LFoMPRQ"
   },
   "outputs": [],
   "source": [
    "X = xdf.iloc[df['v1'].iloc[np.append(df[df['v1']  == 0].index[:100], \n",
    "          df[df['v1']  == 1].index[:100]\n",
    "          )] , \n",
    "       : \n",
    "       ]\n",
    "# now adding saving the processed input  values in the X  variables. To save time, we are just selecting 100 samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "2_o7zXpBrodJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10) #creating an object of PCA (Principal Component Analysis) n_components means in how much columns we need to converge our actual X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "QO4cyVVlsww4"
   },
   "outputs": [],
   "source": [
    "X = pca.fit_transform(X) # wtih the help of fit_transform function, we are converging all the information of the dataset in to 10 columsn, where in original we have 10,000 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "COf1DgZM4Mme"
   },
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "  \n",
    "  for j in range(5):\n",
    "    index = np.random.randint(0,X.shape[1]) #applying some noise in the dataset \n",
    "    X[i,index] = np.random.randn(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGpbP8OLQRKc"
   },
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "2eECEyd5MTn0"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IuLzLiAoN5ug",
    "outputId": "3de525e3-56d6-4f35-957c-7f023e5fbc22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_YZ9UyGOJkH",
    "outputId": "18251d04-43b9-43c6-ec48-498ba8b9e61d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1    100\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "S8s5zdhgRFMf"
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size = .30, random_state = 0) #splitting the X,Y data into train and test size with the ratio .30. Which in actual is 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HveoHWFORQk",
    "outputId": "0cb0f862-21b3-444a-da79-75f63c217aef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB() #creating an object of GaussianNb model with its default parameters\n",
    "model.fit(xtrain, ytrain) #fitting/training the naive bayes model on Xtrain and ytrtain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "At2U2SkAQfbL",
    "outputId": "52e8c324-7d69-49a0-d3df-1f60d3a3ea6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score  #to calculate accuracy, we are importing accuracy_score evaluate the performance of out model\n",
    "score = accuracy_score(ytest, model.predict(xtest)) #passing the xtest data to get the predicted outputs/classes and then passing the real output and predicted output to calcualte the accuracy\n",
    "print(\"Accuracy_score: {} %\".format(score*100)) #displaying the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njy3CoZHPaxJ"
   },
   "source": [
    "## SVMNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "WcKE3b0NPaep"
   },
   "outputs": [],
   "source": [
    "def GetDistance(i, j,data):\n",
    "  submission = np.sum(data.iloc[i,:] - data.iloc[j,:]) ** 2\n",
    "  sub = np.sqrt(submission)\n",
    "  return sub\n",
    "\n",
    "\n",
    "distance = {} #empty dictionary to save distances in key:value pair\n",
    "#creating the SVMNB model\n",
    "def SVMNB(X, Y, V, M):\n",
    "  X = pd.DataFrame(X) #creating X data into dataframe for a safe side\n",
    "  Y = np.array(Y) #converting Y data into an array\n",
    "  V_index = [] #an empty variable to save indexs\n",
    "  for i in range(M): #looping from 0 to M\n",
    "    for j in range(M): #looping from 0 to M\n",
    "      if i != j: #if the value of i is not equal to j\n",
    "        distance[f'{i},{j}'] = GetDistance(i,j,X) #then we will pass these parameters (i,j,X) X is the data in the get distance function and then we will save the distance inthe distance distionary as a key/value pair\n",
    "  for i in range(M): #looping from value 0 to M\n",
    "    Min = 0.0 \n",
    "    NearestNeighbour = i \n",
    "    for j in range(M): #looping from value 0 to M\n",
    "      if i != j:#if the value of i is not equal to j\n",
    "        if Min > float(distance[f'{i},{j}']): #check if the minimum value assigned about in this cell on line 20 is greater then the distance of index i and j \n",
    "          Min = distance[f'{i},{j}'] #if min is greater, then we will assign it to the respective distance value of i and j \n",
    "          NearestNeighbour = j  #assigning the j value as the nearest neighbour\n",
    "  for i in range(M): #looping from value 0 to M\n",
    "    if Y[i] == V[i]:  #if the predicted ith value of Y and V is equal\n",
    "      V_index.append(i) #append the i value into V_index \n",
    "  return V_index, NearestNeighbour #returning the indexes and nearestneighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "yvffG0ArAHZB"
   },
   "outputs": [],
   "source": [
    "V, _ = SVMNB(X, Y, model.predict(X), len(X)) #calling the SVMNB function by passing the xdata, ydata, predicted outputs and length of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNw8RwV9PNTw",
    "outputId": "36c4aa35-84ac-47be-ffba-fcd61cdddc96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB() #again creating an object of GaussianNb model with its default parameters\n",
    "model.fit(pd.DataFrame(X).iloc[np.unique(V),:],\n",
    "          Y.reset_index(drop=True)[np.unique(V)]) #fitting the model with new index values received from the above SVMNB Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qguOrvOsS0Z9",
    "outputId": "c0ee6f2c-778b-452c-a57a-6f72f1745275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 94.83870967741936 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score #to calculate accuracy, we are importing accuracy_score evaluate the performance of out model\n",
    "score = accuracy_score(  Y.reset_index(drop=True)[np.unique(V)], model.predict(pd.DataFrame(X).iloc[np.unique(V),:]))\n",
    "print(\"Accuracy_score: {} %\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHMUkUetHJJ3",
    "outputId": "624fd504-9d08-414b-8203-a68bdf9a2467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        80\n",
      "           1       0.97      0.92      0.95        75\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.95      0.95      0.95       155\n",
      "weighted avg       0.95      0.95      0.95       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report #to calculate classification report, we are importing accuracy score evaluate the overall performance of out model\n",
    "print(classification_report(  Y.reset_index(drop=True)[np.unique(V)], model.predict(pd.DataFrame(X).iloc[np.unique(V),:]))) # creating a classification report  by passing the real and predicted values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rZnN_T0TFxz",
    "outputId": "9223340b-e7bf-49be-e8a7-086bed9faac8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    80\n",
       "1    75\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.reset_index(drop=True)[np.unique(V)].value_counts() #displaying the count of samples with respect to each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjKk1LmmEarx"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGfUk8EFOvUX"
   },
   "source": [
    "This is the testing part, where we are selecting the data from in between then them testing them out.\n",
    "- in the for loop, we are iterating indexes from a certain index range.\n",
    "- then we are select the text in line 2 of the corresponding index value\n",
    "- in line 3 we are converting the text into columns through create column function\n",
    "- in line 7-8, we are adding some noise in the dataset \n",
    "- in line 9, we are applying PCA to converge the information from 10,000 columns into 10 columns and then passing into the model to for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzE-CqMwEjP3",
    "outputId": "87200e05-5a44-40d0-b712-c27d7da41398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(400,600):\n",
    "  TEXT = df.iloc[i,1]\n",
    "  xdf = CreateColumns(getIndices(TEXT, vocab), vocab_length)\n",
    "  for i in range(len(X)):\n",
    "    \n",
    "    for j in range(5):\n",
    "      index = np.random.randint(0,len(xdf))\n",
    "      xdf[index] = np.random.randn(1)\n",
    "  print(model.predict(pca.transform([xdf])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7z0pWhtGE-eg",
    "outputId": "83c74ddd-92d9-4988-a860-15914cea0689"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = 'Ok lar... Joking wif u oni...'\n",
    "xdf = CreateColumns(getIndices(TEXT, vocab), vocab_length)\n",
    "xdf = pca.transform([xdf])\n",
    "for i in range(len(X)):\n",
    "  for j in range(5):\n",
    "    index = np.random.randint(0,len(xdf))\n",
    "    xdf[index] = np.random.randn(1)\n",
    "model.predict(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWN27_y6FRWh",
    "outputId": "43ed22a4-cdf1-4d4d-813c-273914dfc2e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Ã¥Â£1.50 to rcv\"\n",
    "xdf = CreateColumns(getIndices(TEXT, vocab), vocab_length)\n",
    "xdf = pca.transform([xdf])\n",
    "for i in range(len(X)):\n",
    "  for j in range(5):\n",
    "    index = np.random.randint(0,len(xdf))\n",
    "    xdf[index] = np.random.randn(1)\n",
    "model.predict(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZ-omqyoF18Z",
    "outputId": "243a410a-d640-4a64-aff6-30c67378a2ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = \"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\"\n",
    "xdf = CreateColumns(getIndices(TEXT, vocab), vocab_length)\n",
    "xdf = pca.transform([xdf])\n",
    "for i in range(len(X)):\n",
    "  for j in range(5):\n",
    "    index = np.random.randint(0,len(xdf))\n",
    "    xdf[index] = np.random.randn(1)\n",
    "model.predict(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A69tLFmgGJum",
    "outputId": "12386507-6f43-4489-9012-610ebcc5f6d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = \"Nah I don't think he goes to usf, he lives around here though\"\n",
    "xdf = CreateColumns(getIndices(TEXT, vocab), vocab_length)\n",
    "xdf = pca.transform([xdf])\n",
    "for i in range(len(X)):\n",
    "  for j in range(5):\n",
    "    index = np.random.randint(0,len(xdf))\n",
    "    xdf[index] = np.random.randn(1)\n",
    "model.predict(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "wqIG_dD9TS1P",
    "outputId": "7274653d-bd4e-4162-de0d-fb9faf9e3547"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b86f16eb-c7af-41a8-9802-2ac714f50cf2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b86f16eb-c7af-41a8-9802-2ac714f50cf2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b86f16eb-c7af-41a8-9802-2ac714f50cf2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b86f16eb-c7af-41a8-9802-2ac714f50cf2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro...\n",
       "5   1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   0  Even my brother is not like to speak with me. ...\n",
       "7   0  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   1  WINNER!! As a valued network customer you have...\n",
       "9   1  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "42eMZvQfUGCu"
   },
   "outputs": [],
   "source": [
    "#set actual labels and predicted labels and pass through confusion matrix and saved in a variable\n",
    "conf_matrix = confusion_matrix(y_true= Y.reset_index(drop=True)[np.unique(V)], y_pred=model.predict(pd.DataFrame(X).iloc[np.unique(V),:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "aRZoGYujA-yj",
    "outputId": "51877638-5e78-471f-dc4d-9aa6ad853b5d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#passing above variable in which results of confusion matrix are save and displaying the confusion matrix through plot\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "MIjeQZT5B4ws",
    "outputId": "059f1777-05c2-4ede-f381-38ffb0ea61ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfDUlEQVR4nO3de5hddX3v8fcne3LPzOwtiQpJSPYoPBjvNEWFVlFRgQpUPbWgPB6shWpFe9TyFLX1glbt8WjP41M8EisF8YKIHk5soxwElOoBJchFA0XTkIQEkBFmcp3JZGa+54+1dtiZTDJ7Lmuvffm8nmc/2Xuttdf6rgTmM+t3WUsRgZmZta9ZeRdgZmb5chCYmbU5B4GZWZtzEJiZtTkHgZlZm3MQmJm1OQeBNQ1Jb5X0f2vY7kuS/q4eNdWDpM2STkvff0zS1/KuyVqLg8BmRPrDakDSbkm/lXSVpEUzeYyI+HpEvLaG7d4ZEZ+YyWNXSApJe9Lz3C7p85IKWRxrKiR1SfqfkramNf5n+nlx3rVZ43IQ2Ew6KyIWAScCq4G/HbuBpI66VzXzXpie5yuAPwX+LOd6AJA0B7gZeC5wOtAFvAx4AjhpCvtrhX8rq4GDwGZcRGwHvg88Dw78Fv1uSb8BfpMue72keyT1S/p/kl5Q+b6k5ZK+K6lX0hOS/ildfoGkn6TvJekfJT0uaaekX0qqHO8qSZ+s2t+FkjZKelLSWknHVK0LSe+U9Ju0lsslqcbz3Aj8FHhR1f6mcl7PknRLuux3kr4uqTjpv3h4G3As8IaIuD8iRiPi8Yj4RESsqzrfZ1fVdODvStKpkrZJ+htJjwH/IukBSa+v2r4jrf/E9PNL0/Psl3SvpFOnULflzEFgM07ScuBM4O6qxX8MvARYJenFwJXAXwBHAVcAayXNTZtZ/hXYAqwElgLXjnOY1wIvB44HuoE3k/zmO7aWVwGfTtcfne537P5eD/w+8IJ0u9fVeJ4nAH8IbEw/T/W8lNZ4DPAcYDnwsVpqGOM04AcRsXsK3614JvA0YAVwEfBN4Lyq9a8DfhcRv5C0FPg34JPpd/4a+I6kJdM4vuXAQWAz6QZJ/cBPgB8Dn6pa9+mIeDIiBkh+wFwRET+LiJGIuBrYB7yUpAnjGOCSiNgTEYMR8ZNxjrUf6AROABQRD0TEo+Ns91bgyoj4RUTsAz4IvEzSyqptPhMR/RGxFbiVqt/wD+MXkvYADwA/Ar6YLp/SeUXExoi4KSL2RUQv8HmSZqfJOgoY7+9gMkaBj6a1DADfAM6WtCBd/xaScAA4H1gXEevSq4+bgPUkvwRYE3EQ2Ez644goRsSKiPjL9AdJxcNV71cAH0ibE/rT8FhO8oNyObAlIoaPdKCIuAX4J+By4HFJayR1jbPpMSS/hVe+t5vkymFp1TaPVb3fCywCkLQh7XDdLekPq7Y5Md3mT0muchZO57wkPUPStWnn807ga8BUOnefILnqmY7eiBisfEibvx4AzkrD4GyScIDkfP9kzPn+wQzUYHXmILB6qb7N7cPA36ehUXktiIhvpuuOraWjMiK+EBG/B6wiaSK6ZJzNHiH5gQWApIUkvzlvr2H/z42IRenr38esi4i4Drgd+Mg0z+tTJH8/z4+ILpLftGvqpxjjh8Dr0nM8nL3AgqrPzxyzfrzbEVeah84B7k/DAZJzumbM+S6MiM9MoXbLkYPA8vBl4J2SXpJ2+i6U9EeSOoGfkzRvfCZdPk/SKWN3IOn30+/PBvYAgyTNGmN9E3i7pBdJmkvyQ/dnEbF5hs7lM8CFkp45jfPqBHYDO9J29/ECrRbXkPxw/o6kEyTNknSUpA9JqjTX3AO8RVJB0unU1gR1LUmfzLt46moAkiuXsyS9Lt3fvLTDedkU67ecOAis7iJiPXAhSdNOH0ln6wXpuhHgLODZwFZgG0kTzFhdJD94+0iafp4APjvOsX4I/B3wHZIfxM8Czp3Bc/klcBtJ2/9Uz+vjJM1NO0g6X787xVr2kXQY/wdwE7CTJIAWAz9LN/urtI5+kv6TG2rY76MkVz4nA9+qWv4wyVXCh4BekhC6BP9caTryg2nMzNqbk9vMrM05CMzM2pyDwMyszTkIzMzaXNPdVGrx4sWxcuXKvMswM2sqd9111+8iYtzbfzRdEKxcuZL169fnXYaZWVORtOVw69w0ZGbW5hwEZmZtzkFgZtbmHARmZm3OQWBm1uYyCwJJVyp5jOCvDrNekr6g5BGC91UefWdmZvWV5RXBVSQP0D6cM4Dj0tdFwP/KsBYzMzuMzOYRRMRtYx4HONY5wFcjuf3pHZKKko4+zOMGp23rT7ay6Yeb6JjfwewFs8d/zT90Wce8DjRrKs8IMTNrDnlOKFvKwY8v3JYuOyQIJF1EctXAscceO6WDPXz7w/z44z+e0ncPhMc4QXEgMI4QMLWEjwPHzPLSFDOLI2INsAZg9erVU3qAwimXnMLJHziZ4cFh9u/df/BrYP+hy6pewwPjfGfvfob2DLH3d3sP3X7wiI/bPaxxA2NM+HQs6DjsulrCp2NeB5IDx8yekmcQbCd5oHfFMmp4jux0aJYO/EDMUowG+wcOHyAThc/w3uGD1g/tGWJP755DgmlGA2dM+BwUOBM0n40XPg4cs+aRZxCsBS6WdC3wEmBHVv0D9aZZYs7COcxZOCfT41QCp9YrmLEBNLz34O2Gdg+x5/E9h3xnZN/IlOqruXmsxuaz8V6FuQUHjtk0ZRYEkr4JnAoslrQN+CgwGyAivgSsA84kea7rXuDtWdXSquoVOKMjo0m4HOkq5gjhM3bd0K4h9vx2zyHBNKXAEZn23ThwrB1kOWrovAnWB/DurI5vM2dWYRZzFs1hzqI6BU6tTWgThM++nfvY/djuQ69whqYYOLU0jy3omHIwzZ7vwLF8NEVnsbWHXANnGuEzuGOQXY/uOmT9tAOn1kEDUxg4UJjjwLGnOAis7dQtcIZHD+6TmWT4HNSHM3Bw4FS/RvePTrq2ysCJrPpuKt9z4DQHB4FZRmZ1zGJu51zmds7N9DhjA6fmgQNpwIwdNDDYN8iu7bsO2ed0AifrgQOzZs9y4EyDg8CsydUrcEb2jzwVLFOce1O97kDgjAmmKQVOQVPvm5lE+LRq4DgIzKwmhdkFCrMLzO2qY+DU2HdzpPDZ+8TeQ0eu7RkiRiY/N1UFHTYknnb80zjrirOa8g4BDgIzayj1DJxam8/GDZ6qiZ87tuxgy21bePmHX05xZTHTurPgIDCztlSYXaDQXYDu6e9r082buOa0a+h7qK8pg8APpjEzm6ZSuQRA/0P9OVcyNQ4CM7Np6lrehQqib1Nf3qVMiYPAzGyaCrMLdC/v9hWBmVk7K5aL9D3kKwIzs7ZV6im5acjMrJ0Vy8UDd9VtNg4CM7MZUBk51IzNQw4CM7MZUOpp3iGkDgIzsxlQLCcTyXxFYGbWphY+fSGzF8xuyg5jB4GZ2QyQRLFcdNOQmVk7K5VLDgIzs3ZW7CnSt6mP5JHszcNBYGY2Q0rlEkO7hxh4YiDvUibFQWBmNkOadeSQg8DMbIZU5hI028ghB4GZ2Qxp1ucSOAjMzGbInEVzWLB4gZuGzMzaWamnRP8mXxGYmbWtZnwugYPAzGwGFctFdmzZwejIaN6l1MxBYGY2g0o9JUaHR9m5bWfepdQs0yCQdLqkByVtlHTpOOtXSLpZ0n2SfiRpWZb1mJllrRlHDmUWBJIKwOXAGcAq4DxJq8Zs9j+Ar0bEC4DLgE9nVY+ZWT0041yCLK8ITgI2RsSmiBgCrgXOGbPNKuCW9P2t46w3M2sqXcu70Cw1VYdxlkGwFHi46vO2dFm1e4E3pu/fAHRKOirDmszMMlWYXaBreZebhibhr4FXSLobeAWwHRgZu5GkiyStl7S+t7e33jWamU1KqafkpqHUdmB51edl6bIDIuKRiHhjRLwY+HC67JAYjYg1EbE6IlYvWbIkw5LNzKav2R5Qk2UQ3AkcJ6ksaQ5wLrC2egNJiyVVavggcGWG9ZiZ1UWpXGL3Y7vZv3d/3qXUJLMgiIhh4GLgRuAB4LqI2CDpMklnp5udCjwo6dfAM4C/z6oeM7N6qYwc6t/cHFcFHVnuPCLWAevGLPtI1fvrgeuzrMHMrN6qn0uwZFXjN2fn3VlsZtZymm1SmYPAzGyGLXzGQjrmdzTNyCEHgZnZDJNEqVzyFYGZWTtrpttROwjMzDJQmVQWEXmXMiEHgZlZBorlIkO7hhh4ciDvUibkIDAzy8CBuQRN0E/gIDAzy0BlCGkzjBxyEJiZZaB6UlmjcxCYmWVgbudcFixe4CsCM7N21ix3IXUQmJllpFkmlTkIzMwyUuwp0r+ln9GR0bxLOSIHgZlZRkrlEqP7R9m1fVfepRyRg8DMLCPNMnLIQWBmlpHKpLJGHznkIDAzy0j3sd1olhq+w9hBYGaWkcLsAl3LuhwEZmbtrHIX0kbmIDAzy1AzPJfAQWBmlqFST4ndj+5m/8D+vEs5LAeBmVmGKkNI+zc3bj+Bg8DMLEOV21E3coexg8DMLEMH5hI0cD+Bg8DMLEMLn7GQjvkdDT1yyEFgZpYhSRRXNvbtqB0EZmYZa/S5BA4CM7OMVR5QExF5lzIuB4GZWcZK5RL7du5jsG8w71LG5SAwM8tYo9+FNNMgkHS6pAclbZR06Tjrj5V0q6S7Jd0n6cws6zEzy0OjP5cgsyCQVAAuB84AVgHnSVo1ZrO/Ba6LiBcD5wJfzKoeM7O8NPqksiyvCE4CNkbEpogYAq4FzhmzTQBd6ftu4JEM6zEzy8XcrrnMP2p+WzYNLQUervq8LV1W7WPA+ZK2AeuA94y3I0kXSVovaX1vb28WtZqZZapULrXlFUEtzgOuiohlwJnANZIOqSki1kTE6ohYvWTJkroXaWY2XaWeUvv1EQDbgeVVn5ely6q9A7gOICJuB+YBizOsycwsF8Vykf7N/YyOjOZdyiFqCgJJp0i6SdKvJW2S9JCkTRN87U7gOEllSXNIOoPXjtlmK/Dq9BjPIQkCt/2YWcsplouM7h9l1yO78i7lEB01bvcV4H3AXcBILV+IiGFJFwM3AgXgyojYIOkyYH1ErAU+AHxZ0vtIOo4viEademdmNg2VuQT9D/XTvbw752oOVmsQ7IiI70925xGxjqQTuHrZR6re3w+cMtn9mpk1m8oQ0r5Nfax4+YqcqzlYrUFwq6TPAt8F9lUWRsQvMqnKzKzFdB/bDWrMSWW1BsFL0j9XVy0L4FUzW46ZWWsqzCnQvby7IYeQ1hQEEfHKrAsxM2t1xXKxISeV1TpqqFvS5yuTuiR9TlJj9XaYmTW4Rp1UVus8giuBXcCb09dO4F+yKsrMrBUVe4rsemQX+wf2513KQWrtI3hWRLyp6vPHJd2TRUFmZq2qMnJox5YdLD6hcebO1npFMCDpDyofJJ0CDGRTkplZazrwXIIGGzlU6xXBu4Cr034BAU8CF2RVlJlZKzrwXIIG6zCuddTQPcALJXWln3dmWpWZWQta9MxFdMzraLgO4yMGgaTzI+Jrkt4/ZjkAEfH5DGszM2spkg48yL6RTHRFsDD9szPrQszM2kGpXGqupqGIuCL98+P1KcfMrLUVy0W2/nRr3mUcpNYJZf9dUpek2ZJultQr6fysizMzazWlnhL7duxjoK9xBl7WOnz0tWkH8euBzcCzgUuyKsrMrFU14sihWoOg0oT0R8C3I2JHRvWYmbW0yqSyRuowrnUewb9K+g+SSWTvkrQEGMyuLDOz1nTgiqCBJpXVdEUQEZcCJwOrI2I/sAc4J8vCzMxa0bzuecx/2vyGahqaaB7BqyLiFklvrFpWvcl3syrMzKxVNdpcgomahl4B3AKcNc66wEFgZjZppZ4Sv733t3mXccBE8wg+mv759vqUY2bW+orlIg/+nweJ0UCzNPEXMlbrPIJPSSpWfS5J+mR2ZZmZta5ST4mRoRF2PbIr71KA2oePnhERBxq0IqIPODObkszMWltlCGmjdBjXGgQFSXMrHyTNB+YeYXszMzuMRhtCWus8gq8DN0uqPJ7y7cDV2ZRkZtbaiiuKoMaZVFbr8wj+QdK9wGnpok9ExI3ZlWVm1roKcwp0LetqmKahWq8IAB4AhiPih5IWSOqMiMbo6TAzazKlcqlhrghqHTV0IXA9cEW6aClwQ1ZFmZm1ulJPqWH6CGrtLH43cAqwEyAifgM8PauizMxaXbFcZNf2XQwPDuddSs1BsC8ihiofJHWQzCw2M7MpqIwc6t+Sf/NQrUHwY0kfAuZLeg3wbeB7E31J0umSHpS0UdKl46z/R0n3pK9fS8r/b8TMrA5KPY1zO+paO4v/Bvhz4JfAXwDrgH8+0hckFYDLgdcA24A7Ja2NiPsr20TE+6q2fw/w4klVb2bWpBppUtmEQZD+QN8QEScAX57Evk8CNkbEpnQ/15Lcuvr+w2x/HvDRSezfzKxpLXrmIgpzCw3RYTxh01BEjAAPSjp2kvteCjxc9XlbuuwQklYAZZI7nY63/iJJ6yWt7+3tnWQZZmaNR7PUMENIa20aKgEbJP2c5KE0AETE2TNUx7nA9WnoHCIi1gBrAFavXu1OajNrCcVysTmahlJ/N4V9bweWV31eli4bz7kkQ1TNzNpGqafEttu35V3GhE8omwe8E3g2SUfxVyKi1kGvdwLHSSqTBMC5wFvGOcYJJFcct0+ibjOzplcsFxnsH2Sgb4D5pfm51TFRH8HVwGqSEDgD+FytO04D42LgRpLbU1wXERskXSapuknpXODaiHCTj5m1lcrIobz7CSZqGloVEc8HkPQV4OeT2XlErCMZalq97CNjPn9sMvs0M2sVlbkEfQ/1cfSJR+dWx0RXBPsrbybRJGRmZjU48FyCnDuMJ7oieKGknel7kcws3pm+j4joyrQ6M7MWNq97HvNK8xq7aSgiCvUqxMysHZV68p9LUOu9hszMLAOlcin3piEHgZlZjorlIv2b+4nR/AZOOgjMzHJU6ikxMjTCrkfze+Cjg8DMLEeNMHLIQWBmlqNGmFTmIDAzy1H3im4Qud6O2kFgZpajjrkddC3ton+TrwjMzNpWqafkKwIzs3ZWLBfdR2Bm1s6K5SI7t+9keF8+t3RzEJiZ5azUU4KAHVt25HJ8B4GZWc4qQ0jz6idwEJiZ5SzvSWUOAjOznHUe3UlhbiG3DmMHgZlZzjRLFFcWfUVgZtbOSuX8nkvgIDAzawDFnqI7i83M2lmpXGKwb5DB/sG6H9tBYGbWAEo9+Q0hdRCYmTWAyhDSPPoJHARmZg3gwKSyHEYOOQjMzBrAvOI85pXmuWnIzKyd5TWE1EFgZtYgiuV8JpU5CMzMGkSpp0T/5n5iNOp6XAeBmVmDKJaLjOwbYfdju+t63EyDQNLpkh6UtFHSpYfZ5s2S7pe0QdI3sqzHzKyR5TVyKLMgkFQALgfOAFYB50laNWab44APAqdExHOB/5ZVPWZmjS6vSWVZXhGcBGyMiE0RMQRcC5wzZpsLgcsjog8gIh7PsB4zs4bWvaIbVP9JZVkGwVLg4arP29Jl1Y4Hjpf0U0l3SDp9vB1JukjSeknre3t7MyrXzCxfHXM76Dyms3WahmrUARwHnAqcB3xZUnHsRhGxJiJWR8TqJUuW1LlEM7P6KfXUfy5BlkGwHVhe9XlZuqzaNmBtROyPiIeAX5MEg5lZWyqVSy11RXAncJyksqQ5wLnA2jHb3EByNYCkxSRNRZsyrMnMrKEVe4rs3L6T4X3DdTtmZkEQEcPAxcCNwAPAdRGxQdJlks5ON7sReELS/cCtwCUR8URWNZmZNbpSuQQBO7buqNsxO7LceUSsA9aNWfaRqvcBvD99mZm1vcrtqPs29XHUcUfV5Zh5dxabmVmVylyCenYYOwjMzBpI59GdFOYW6jqpzEFgZtZANEsUVxTp3+QrAjOztlXqKfmKwMysnRXLRfcRmJm1s2K5yMCTAwzuGKzL8RwEZmYNpt4jhxwEZmYN5sBzCerUT+AgMDNrMNWTyurBQWBm1mDml+YzrzjPTUNmZu2sniOHHARmZg2o1FO/21E7CMzMGlCxXKR/cz8xGpkfy0FgZtaASuUSw4PD7H5sd+bHchCYmTWgylyCegwhdRCYmTWgyhDSenQYOwjMzBpQcUX95hI4CMzMGlDHvA46l3b6isDMrJ2VyvW5HbWDwMysQRXLRTcNmZm1s1JPiZ3bdjIyNJLpcRwEZmYNqlguQsCOrTsyPY6DwMysQR24HXXGzUMOAjOzBlWvSWUOAjOzBtV5TCeFOYXMh5A6CMzMGpRmieLK7EcOOQjMzBpYPZ5L4CAwM2tg9ZhL4CAwM2tgpZ4SA08OsG/nvsyO4SAwM2tgB4aQZjhyKNMgkHS6pAclbZR06TjrL5DUK+me9PXnWdZjZtZsKrejzrJ5qCOrHUsqAJcDrwG2AXdKWhsR94/Z9FsRcXFWdZiZNbPKXIIsO4yzvCI4CdgYEZsiYgi4Fjgnw+OZmbWc+aX5zO2e27RNQ0uBh6s+b0uXjfUmSfdJul7S8vF2JOkiSeslre/t7c2iVjOzhlUql+jf1JxXBLX4HrAyIl4A3ARcPd5GEbEmIlZHxOolS5bUtUAzs7yVerJ9LkGWQbAdqP4Nf1m67ICIeCIiKmOi/hn4vQzrMTNrSpVJZRGRyf6zDII7geMklSXNAc4F1lZvIOnoqo9nAw9kWI+ZWVMq9ZQYHhxm92O7M9l/ZqOGImJY0sXAjUABuDIiNki6DFgfEWuB90o6GxgGngQuyKoeM7NmVRlC2v9QP51Hd874/jMLAoCIWAesG7PsI1XvPwh8MMsazMyaXfWksuUnjzumZlry7iw2M7MJFFcWOf6s41mweEEm+8/0isDMzKavY14H5609L7P9+4rAzKzNOQjMzNqcg8DMrM05CMzM2pyDwMyszTkIzMzanIPAzKzNOQjMzNqcsrqbXVYk9QJbpvj1xcDvZrCcZuBzbg8+5/YwnXNeERHj3se/6YJgOiStj4jVeddRTz7n9uBzbg9ZnbObhszM2pyDwMyszbVbEKzJu4Ac+Jzbg8+5PWRyzm3VR2BmZodqtysCMzMbw0FgZtbmWjIIJJ0u6UFJGyVdOs76uZK+la7/maSV9a9yZtVwzu+XdL+k+yTdLGlFHnXOpInOuWq7N0kKSU0/1LCWc5b05vTfeoOkb9S7xplWw3/bx0q6VdLd6X/fZ+ZR50yRdKWkxyX96jDrJekL6d/HfZJOnPZBI6KlXkAB+E+gB5gD3AusGrPNXwJfSt+fC3wr77rrcM6vBBak79/VDuecbtcJ3AbcAazOu+46/DsfB9wNlNLPT8+77jqc8xrgXen7VcDmvOue5jm/HDgR+NVh1p8JfB8Q8FLgZ9M9ZiteEZwEbIyITRExBFwLnDNmm3OAq9P31wOvlqQ61jjTJjzniLg1IvamH+8AltW5xplWy78zwCeAfwAG61lcRmo55wuByyOiDyAiHq9zjTOtlnMOoCt93w08Usf6ZlxE3AY8eYRNzgG+Gok7gKKko6dzzFYMgqXAw1Wft6XLxt0mIoaBHcBRdakuG7Wcc7V3kPxG0cwmPOf0knl5RPxbPQvLUC3/zscDx0v6qaQ7JJ1et+qyUcs5fww4X9I2YB3wnvqUlpvJ/v8+IT+8vs1IOh9YDbwi71qyJGkW8HnggpxLqbcOkuahU0mu+m6T9PyI6M+1qmydB1wVEZ+T9DLgGknPi4jRvAtrFq14RbAdWF71eVm6bNxtJHWQXE4+UZfqslHLOSPpNODDwNkRsa9OtWVlonPuBJ4H/EjSZpK21LVN3mFcy7/zNmBtROyPiIeAX5MEQ7Oq5ZzfAVwHEBG3A/NIbs7Wqmr6/30yWjEI7gSOk1SWNIekM3jtmG3WAv81ff9fgFsi7YVpUhOes6QXA1eQhECztxvDBOccETsiYnFErIyIlST9ImdHxPp8yp0Rtfy3fQPJ1QCSFpM0FW2qZ5EzrJZz3gq8GkDSc0iCoLeuVdbXWuBt6eihlwI7IuLR6eyw5ZqGImJY0sXAjSQjDq6MiA2SLgPWR8Ra4Cskl48bSTplzs2v4umr8Zw/CywCvp32i2+NiLNzK3qaajznllLjOd8IvFbS/cAIcElENO3Vbo3n/AHgy5LeR9JxfEEz/2In6ZskYb447ff4KDAbICK+RNIPciawEdgLvH3ax2zivy8zM5sBrdg0ZGZmk+AgMDNrcw4CM7M25yAwM2tzDgIzszbnIDAbh6QRSfdI+pWk70kqzvD+N6fj/JG0eyb3bTZZDgKz8Q1ExIsi4nkkc03enXdBZllxEJhN7HbSm3pJepakH0i6S9K/SzohXf4MSf9b0r3p6+R0+Q3pthskXZTjOZgdVsvNLDabSZIKJLcv+Eq6aA3wzoj4jaSXAF8EXgV8AfhxRLwh/c6idPs/i4gnJc0H7pT0nWae6WutyUFgNr75ku4huRJ4ALhJ0iLgZJ66TQfA3PTPVwFvA4iIEZJbmwO8V9Ib0vfLSW4A5yCwhuIgMBvfQES8SNICkvvcvBu4CuiPiBfVsgNJpwKnAS+LiL2SfkRyQzSzhuI+ArMjSJ/q9l6SG5vtBR6S9Cdw4NmxL0w3vZnkEaBIKkjqJrm9eV8aAieQ3ArbrOE4CMwmEBF3A/eRPADlrcA7JN0LbOCpxyb+FfBKSb8E7iJ5du4PgA5JDwCfIbkVtlnD8d1HzczanK8IzMzanIPAzKzNOQjMzNqcg8DMrM05CMzM2pyDwMyszTkIzMza3P8HONUEwzw6n5cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(Y.reset_index(drop=True)[np.unique(V)],model.predict(pd.DataFrame(X).iloc[np.unique(V),:]))\n",
    "\n",
    "#create precision recall curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "\n",
    "#display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NU2vg3fVB-B4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
